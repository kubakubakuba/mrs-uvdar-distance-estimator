%!TEX root = ../main.tex

\chapter{Introduction\label{chap:introduction}}

This semestral project is focused on measuring the influence of distance and frequency of modulated
light source on event based camera response. Knowing the parameters of the light source, the camera with the lens
and how the response behaves, it is possible to predict the distance of the light source from the camera. This can be
used to improve the precision of localization algorithms, that are used in \ac{UAV} swarming applications. 

Event based cameras, in contrast to traditional frame based cameras, do not capture still frames but rather
provide an asynchronous and idependent stream of intensity changes on individual pixels.
Each pixel memorizes the last intensity value and sends an event when the intensity changes above a certain threshold.
%\cite{gallego2020event}
Event cameras circumvent many common issues found in traditional frame-based cameras, such as motion blur caused
by fast-moving objects. They offer significant advantages, including a high dynamic range, low latency,
and energy efficiency.
This makes them perfect fot the application of agile robotics,
where the fast response time is crucial (especially in UAV swarming situations). With their sub-millisecond response time,
event cameras can provide a significant advantage over traditional cameras in these applications.
However, they also come with some drawbacks, such as the need for a different approach to
data processing and the higher cost of the camera units themselves. \cite{gallego2020event}

The event data stream is represented by tuples of $(x, y, p, t)$, where $(x, y)$ are the pixel coordinates, $t$ is the time of
intensity change and $p$ is the polarity of the change - the increase or decrease of light intensity. Images can be
reconstructed from the event stream by integrating the events over time, doing so makes the usage of normal vision 
algorithms is possible, but is also goes against the main advantage of the event cameras - the low latency.

\section{Related Works}

The unique capabilities of event-based cameras have been extensively explored in various applications and studies.
A comprehensive survey by Gallego et al. \cite{gallego2020event} highlights the advantages of event cameras in
applications requiring high-speed motion analysis, wide dynamic range, and low power consumption.
%The survey also addresses the challenges of processing the asynchronous and sparse event data these cameras generate, 
%emphasizing the need for novel algorithms tailored to this unconventional sensing paradigm.

The potential of event cameras in vehicular \ac{VLC} has been demonstrated by Shen et al.
\cite{shen2019vehicular}. Their study introduced a framework utilizing a \ac{DVS} to mitigate the limitations of
traditional photodiode- and frame-based camera systems, such as limited throughput and vulnerability to ambient
interference. By leveraging the event-driven nature of DVS, the proposed system achieved significant improvements
in data transmission range and robustness.

In addition to VLC, event-based cameras have been successfully integrated into localization systems, with promising
results in indoor positioning. Bai et al. \cite{bai2021vlp} introduced the enhanced Camera-Assisted \ac{RSSR}
algorithm, which combines visual data from event cameras with signal strength ratios from photodiodes.
This algorithm achieves centimeter-level positioning accuracy while requiring minimal infrastructure,
significantly improving the coverage and accuracy of localization systems. The RSSR approach demonstrates the
potential for precise and efficient positioning in applications such as autonomous navigation and UAV swarming.